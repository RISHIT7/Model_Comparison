{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_data/student-mat.csv')\n",
    "y = df['GPA']\n",
    "x = df.drop(['GPA'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the input features is: {x.shape}\\nThe shape of target parameters is: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training set input feature has size: {x_train.shape}\")\n",
    "print(f\"The training set output parameter has size: {y_train.shape}\")\n",
    "print(f\"The test set input feature has the shape: {x_test.shape}\")\n",
    "print(f\"The test set output parameter has the shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Linear Regression Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a prototype model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(x_train)\n",
    "print(f\"Training MSE: {mean_squared_error(y_train, yhat_train)}\")\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"Testing MSE: {mean_squared_error(y_test, yhat_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = {'1': (4.428325516620169, 5.761991434404496)}\n",
    "for i in range(2, 5):\n",
    "    poly_reg = PolynomialFeatures(degree = i)\n",
    "    x_poly_train = poly_reg.fit_transform(x_train)\n",
    "    x_poly_test = poly_reg.fit_transform(x_test)\n",
    "    model.fit(x_poly_train, y_train)\n",
    "\n",
    "    yhat_train = model.predict(x_poly_train)\n",
    "    yhat_test = model.predict(x_poly_test)\n",
    "    \n",
    "    train_error = mean_squared_error(y_train, yhat_train)\n",
    "    test_error = mean_squared_error(y_test, yhat_test)\n",
    "    \n",
    "    print(\"=\"*20)\n",
    "    print(f\"Polynomial degree: {i}\")\n",
    "    print(f\"Training MSE: {train_error}\")\n",
    "    print(f\"Testing MSE: {test_error}\")\n",
    "    \n",
    "    J[str(i)] = (train_error, test_error)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J.keys(), J.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly degree 1 has the lowest test_error, and due to high variance the test_error increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 10e6)\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree = 2)\n",
    "x_poly_train = poly_reg.fit_transform(x_train)\n",
    "x_poly_test = poly_reg.fit_transform(x_test)\n",
    "ridge.fit(x_poly_train, y_train)\n",
    "\n",
    "mean_squared_error(ridge.predict(x_poly_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the lowest error that we can get from a polynomial reg model... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 10)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"Testing MSE: {mean_squared_error(y_test, yhat_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best we can do from Linear regression model, with Ridge Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(alpha = 10)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"Testing MSE: {mean_squared_error(y_test, yhat_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(alpha = 10)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"Testing MSE: {mean_squared_error(y_test, yhat_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Regression'] = 11.237178423746085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid, softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    \n",
    "    tf.random.set_seed(20)\n",
    "    \n",
    "    model_1 = Sequential(\n",
    "        [\n",
    "            Dense(25, activation = 'relu'),\n",
    "            Dense(15, activation = 'relu'),\n",
    "            Dense(1, activation = 'linear')\n",
    "        ],\n",
    "        name='model_1'\n",
    "    )\n",
    "\n",
    "    model_2 = Sequential(\n",
    "        [\n",
    "            Dense(20, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(20, activation = 'relu'),\n",
    "            Dense(1, activation = 'linear')\n",
    "        ],\n",
    "        name='model_2'\n",
    "    )\n",
    "\n",
    "    model_3 = Sequential(\n",
    "        [\n",
    "            Dense(32, activation = 'relu'),\n",
    "            Dense(16, activation = 'relu'),\n",
    "            Dense(8, activation = 'relu'),\n",
    "            Dense(4, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(1, activation = 'linear')\n",
    "        ],\n",
    "        name='model_3'\n",
    "    )\n",
    "    \n",
    "    model_list = [model_1, model_2, model_3]\n",
    "    \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the above structures, and then choosing the one that gives lowest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "nn_train_mses = []\n",
    "nn_test_mses = []\n",
    "\n",
    "# Build the models\n",
    "nn_models = build_models()\n",
    "\n",
    "# Loop over the models\n",
    "for model in nn_models:\n",
    "\n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "        loss = 'mse',\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    )\n",
    "\n",
    "    print(f\"Training {model.name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs = 300,\n",
    "        verbose = 0,\n",
    "    )\n",
    "\n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    # Record the training MSEs\n",
    "    yhat_train = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, yhat_train)/2\n",
    "    nn_train_mses.append(train_mse)\n",
    "\n",
    "    # Record the cross validation MSEs\n",
    "    yhat_test = model.predict(x_test)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)/2\n",
    "    nn_test_mses.append(test_mse)\n",
    "\n",
    "# print results\n",
    "print(\"RESULTS:\")\n",
    "for model_num in range(len(nn_train_mses)):\n",
    "    print(\n",
    "        f\"Model {model_num+1}: Training MSE: {nn_train_mses[model_num]:.2f}, \" +\n",
    "        f\"Test MSE: {nn_test_mses[model_num]:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L2\n",
    "def build_models(lambda_):\n",
    "    \n",
    "    tf.random.set_seed(20)\n",
    "    \n",
    "    model_1 = Sequential(\n",
    "        [\n",
    "            Dense(25, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(15, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(1, activation = 'linear', kernel_regularizer=L2(lambda_))\n",
    "        ],\n",
    "        name='model_1'\n",
    "    )\n",
    "\n",
    "    model_2 = Sequential(\n",
    "        [\n",
    "            Dense(20, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(12, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(12, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(20, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(1, activation = 'linear', kernel_regularizer=L2(lambda_))\n",
    "        ],\n",
    "        name='model_2'\n",
    "    )\n",
    "\n",
    "    model_3 = Sequential(\n",
    "        [\n",
    "            Dense(32, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(16, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(8, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(4, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(12, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(1, activation = 'linear', kernel_regularizer=L2(lambda_))\n",
    "        ],\n",
    "        name='model_3'\n",
    "    )\n",
    "    \n",
    "    model_list = [model_1, model_2, model_3]\n",
    "    \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "nn_train_mses = []\n",
    "nn_test_mses = []\n",
    "\n",
    "# Build the models\n",
    "nn_models = build_models(0.01)\n",
    "\n",
    "# Loop over the models\n",
    "for model in nn_models:\n",
    "\n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "        loss = 'mse',\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    )\n",
    "\n",
    "    print(f\"Training {model.name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs = 300,\n",
    "        verbose = 0,\n",
    "    )\n",
    "\n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    # Record the training MSEs\n",
    "    yhat_train = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, yhat_train)/2\n",
    "    nn_train_mses.append(train_mse)\n",
    "\n",
    "    # Record the cross validation MSEs\n",
    "    yhat_test = model.predict(x_test)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)/2\n",
    "    nn_test_mses.append(test_mse)\n",
    "\n",
    "# print results\n",
    "print(\"RESULTS:\")\n",
    "for model_num in range(len(nn_train_mses)):\n",
    "    print(\n",
    "        f\"Model {model_num+1}: Training MSE: {nn_train_mses[model_num]:.2f}, \" +\n",
    "        f\"Test MSE: {nn_test_mses[model_num]:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that model three is better... hence we use this model further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lambda_):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(32, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(16, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(8, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(4, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(12, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "            Dense(1, activation = 'linear', kernel_regularizer=L2(lambda_))\n",
    "        ],\n",
    "        name='model_3'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_mses = []\n",
    "nn_test_mses = []\n",
    "lambdas = []\n",
    "\n",
    "for i in range(1, 50, 2):\n",
    "    lambda_ = 0.001*2*i\n",
    "    lambdas.append(lambda_)\n",
    "    model = build_model(lambda_)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'mse',\n",
    "        optimizer = Adam(learning_rate=0.1),\n",
    "    )\n",
    "    print(f\"Training for lambda = {lambda_}...\")\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs = 300,\n",
    "        verbose = 0,\n",
    "    )\n",
    "\n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    yhat_train = model.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, yhat_train)/2\n",
    "    nn_train_mses.append(train_mse)\n",
    "\n",
    "    yhat_test = model.predict(x_test)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)/2\n",
    "    nn_test_mses.append(test_mse)\n",
    "\n",
    "print(\"RESULT:\")\n",
    "idx = 0\n",
    "for lambda_ in lambdas:\n",
    "    print(\n",
    "        f\"Lambda = {lambda_}:\\nTraining MSE: {nn_train_mses[idx]:.2f}, \" +\n",
    "        f\"Test MSE: {nn_test_mses[idx]:.2f}\"\n",
    "    )\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Above iterations, we choose the lambda value 0.026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.066\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(32, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "        Dense(16, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "        Dense(8, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "        Dense(4, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "        Dense(12, activation = 'relu', kernel_regularizer=L2(lambda_)),\n",
    "        Dense(1, activation = 'linear', kernel_regularizer=L2(lambda_))\n",
    "    ],\n",
    "    name='model_fin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'mse',\n",
    "    optimizer = Adam(learning_rate=0.1),\n",
    ")\n",
    "model.fit(x_train, y_train,\n",
    "          epochs = 300,\n",
    "          verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(x_train)\n",
    "print(f\"The training set error is: {mean_squared_error(y_train, yhat_train)/2}\")\n",
    "\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"The testing set error is: {mean_squared_error(y_test, yhat_test)/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['NN'] = 5.638041873490467"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descision Tree Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = {}\n",
    "for i in range(1, 50, 2):\n",
    "    lambda_ = 0.001*2*i\n",
    "    model = XGBRegressor(n_estimators = 500, learning_rate = 0.1, verbosity = 1, random_state = 0, gamma = lambda_)\n",
    "    model.fit(x_train, y_train, eval_set=[(x_test, y_test)], early_stopping_rounds=10)\n",
    "\n",
    "    yhat_train = model.predict(x_train)\n",
    "    yhat_test = model.predict(x_test)\n",
    "\n",
    "    train_error = mean_squared_error(yhat_train, y_train)\n",
    "    test_error = mean_squared_error(yhat_test, y_test)\n",
    "\n",
    "    J[str(i)] = (train_error, test_error)\n",
    "plt.plot(J.keys(), J.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best is the 31st iteration, 0.062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.001*2*31\n",
    "model = XGBRegressor(n_estimators = 500, learning_rate = 0.1, verbosity = 1, random_state = 0, gamma = lambda_)\n",
    "model.fit(x_train, y_train, eval_set=[(x_test, y_test)], early_stopping_rounds=10)\n",
    "\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(x_train)\n",
    "print(f\"The training set error is: {mean_squared_error(y_train, yhat_train)/2}\")\n",
    "\n",
    "yhat_test = model.predict(x_test)\n",
    "print(f\"The testing set error is: {mean_squared_error(y_test, yhat_test)/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['XGB'] = 5.468958891337183\n",
    "data = {'Model': list(results.keys()), 'Error': list(results.values())}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(df, x = 'Model', y = 'Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
